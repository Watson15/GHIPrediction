{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78b85f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "# from processAllData import getAllReadyForStationByLatAndLongAndK, getAllReadyForStationByLatAndLongAndKSplitTestAndTrain\n",
    "\n",
    "#from LSTMArchitecture import GHIDataset, Main_LSTM\n",
    "import torch.nn as nn\n",
    "import glob # For loading multiple files\n",
    "#import random\n",
    "import os\n",
    "\n",
    "from constants import COLUMN_NAMES\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b8e19e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cyclicalEncoding(data, cycleLength):\n",
    "  newDatasin = np.sin(2 * np.pi * (data - 1) / cycleLength)  # Sine encoding for hours (adjust for 0-23)\n",
    "  newDatacos = np.cos(2 * np.pi * (data - 1) / cycleLength)  # Cosine encoding for hours (adjust for 0-23)\n",
    "  return newDatasin, newDatacos\n",
    "\n",
    "# YEAR_MONTH_DAY_HOUR = COLUMN_NAMES[\"YEAR_MONTH_DAY_HOUR\"]\n",
    "usecols = [\n",
    "    'Year Month Day Hour (YYYYMMDDHH)',\n",
    "    'Opaque sky cover / 0-10 in tenths',\n",
    "    'Global horizontal irradiance / kJ/m2',\n",
    "    'Direct normal irradiance / kJ/m2',\n",
    "    'Diffuse horizontal irradiance / kJ/m2',\n",
    "    'Wind direction / 0-359 degrees',\n",
    "    'Wind speed / 0.1 m/s',\n",
    "    'Dry bulb temperature / 0.1 C',\n",
    "]\n",
    "\n",
    "dtype = {\n",
    "    'Year Month Day Hour (YYYYMMDDHH)': str,  # Read as string initially to handle errors\n",
    "    'Opaque sky cover / 0-10 in tenths': str,\n",
    "    'Global horizontal irradiance / kJ/m2': str,\n",
    "    'Direct normal irradiance / kJ/m2': str,\n",
    "    'Diffuse horizontal irradiance / kJ/m2': str,\n",
    "    'Wind direction / 0-359 degrees': str,\n",
    "    'Wind speed / 0.1 m/s': str,\n",
    "    'Dry bulb temperature / 0.1 C': str,\n",
    "}\n",
    "\n",
    "def fix_opaque_sky_cover(df):\n",
    "  #If opaque sky cover is nan then set to most recent opaque sky cover value as long as its not been more than 3 hours since last value\n",
    "  last_valid_value = None\n",
    "  last_valid_index = -1\n",
    "  num_skipped = 0\n",
    "  min_year = df[COLUMN_NAMES[\"YEAR_MONTH_DAY_HOUR\"]].min()\n",
    "  max_year = df[COLUMN_NAMES[\"YEAR_MONTH_DAY_HOUR\"]].max()\n",
    "  #print(f\"Before fixing opaque sky cover, min year: {min_year}, max year: {max_year}\")\n",
    "  for i in range(len(df)):\n",
    "    if df.at[i, COLUMN_NAMES[\"OPAQUE_SKY_COVER\"]] != 99 and not np.isnan(df.at[i, COLUMN_NAMES[\"OPAQUE_SKY_COVER\"]]):\n",
    "      last_valid_value = df.at[i, COLUMN_NAMES[\"OPAQUE_SKY_COVER\"]]\n",
    "      last_valid_index = i\n",
    "      num_skipped = 0\n",
    "    else:\n",
    "      num_skipped += 1\n",
    "      if last_valid_value is not None and num_skipped < 8:\n",
    "        df.at[i, COLUMN_NAMES[\"OPAQUE_SKY_COVER\"]] = last_valid_value\n",
    "    if num_skipped >= 8:\n",
    "      # More than 8 consecutive invalid entries, stop filling and remove the rest of the rows in the dataframe.\n",
    "      if last_valid_index == -1:\n",
    "        # No valid entries found, return empty dataframe\n",
    "        return df.iloc[0:0], False, False\n",
    "      df = df.iloc[:last_valid_index+5]  # Keep up to 4 hours after the last valid entry\n",
    "      max_year = df[COLUMN_NAMES[\"YEAR_MONTH_DAY_HOUR\"]].max()\n",
    "      break\n",
    "  if np.isnan(max_year):\n",
    "    max_year = min_year\n",
    "  \n",
    "  return df, min_year, max_year\n",
    "\n",
    "def get_stations_data(station_csv):\n",
    "  # Read the CSV file with specified columns and data types\n",
    "  df = pd.read_csv(station_csv, delimiter=',', skiprows=2, index_col=False, usecols=usecols, dtype=dtype, on_bad_lines='skip')\n",
    "  # Convert columns to numeric, coercing errors to NaN\n",
    "  station_name_df = pd.read_csv(station_csv, delimiter=',', nrows=1, usecols=['Climate station name'], on_bad_lines='skip')\n",
    "  station_name = station_name_df.iloc[0, 0]\n",
    "  for col in usecols:\n",
    "    if(col == COLUMN_NAMES[\"YEAR_MONTH_DAY_HOUR\"]):\n",
    "      #keep as string\n",
    "      df[COLUMN_NAMES[\"YEAR_MONTH_DAY_HOUR\"]] = df[col].astype(int)\n",
    "      df[COLUMN_NAMES[\"YEAR_MONTH_DAY_HOUR\"]] = df[COLUMN_NAMES[\"YEAR_MONTH_DAY_HOUR\"]].astype(str)\n",
    "      # Get year (YYYY)\n",
    "      df[COLUMN_NAMES[\"YEAR\"]] = df[COLUMN_NAMES[\"YEAR_MONTH_DAY_HOUR\"]].str[0:4].astype(int)\n",
    "      # Get month (1-12)\n",
    "      df[COLUMN_NAMES[\"MONTH\"]] = df[COLUMN_NAMES[\"YEAR_MONTH_DAY_HOUR\"]].str[4:6].astype(int)\n",
    "      # Get hour (1-24)\n",
    "      df[COLUMN_NAMES[\"HOUR\"]] = df[COLUMN_NAMES[\"YEAR_MONTH_DAY_HOUR\"]].str[8:10].astype(int)\n",
    "      df[COLUMN_NAMES[\"HOUR_SIN\"]], df[COLUMN_NAMES[\"HOUR_COS\"]] = cyclicalEncoding(df[COLUMN_NAMES[\"HOUR\"]], 24)# Sine and Cosine encoding for hours (adjust for 0-23)\n",
    "      # df['Hour_sin'] = np.sin(2 * np.pi * (df['Hour'] - 1) / 24)\n",
    "      # df['Hour_cos'] = np.cos(2 * np.pi * (df['Hour'] - 1) / 24)  # Cosine encoding for hours (adjust for 0-23)\n",
    "      # Normalize month so cyclic (0-11))\n",
    "      df[COLUMN_NAMES[\"MONTH_SIN\"]], df[COLUMN_NAMES[\"MONTH_COS\"]] = cyclicalEncoding(df[COLUMN_NAMES[\"MONTH\"]], 12)# Sine and Cosine encoding for months\n",
    "      df[COLUMN_NAMES[\"YEAR_MONTH_DAY_HOUR\"]] = df[col].astype(int)\n",
    "      #df = df.drop(columns=[col], axis=1)\n",
    "      continue\n",
    "\n",
    "    if (col == 'Opaque sky cover / 0-10 in tenths'):\n",
    "      df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "      #Skip rest here and handle later for df_cloud\n",
    "      continue\n",
    "\n",
    "    if(col=='Wind direction / 0-359 degrees'):\n",
    "      df[col] = pd.to_numeric(df[col], errors='coerce').replace(99, np.nan)\n",
    "      radians = np.deg2rad(df[col])\n",
    "      df[COLUMN_NAMES[\"WIND_DIRECTION_SIN\"]] = np.sin(radians)\n",
    "      df[COLUMN_NAMES[\"WIND_DIRECTION_COS\"]] = np.cos(radians)\n",
    "      #df = df.drop(columns=[col], axis=1)\n",
    "      continue\n",
    "\n",
    "    if(col == 'Dry bulb temperature / 0.1 C'):\n",
    "      df[col] = pd.to_numeric(df[col], errors='coerce').replace(999, np.nan)\n",
    "      # mean = df[col].mean()\n",
    "      # std = df[col].std()\n",
    "      # df[col] = (df[col] - mean) / std\n",
    "      continue\n",
    "\n",
    "    if(col == 'Wind speed / 0.1 m/s'):\n",
    "      df[col] = pd.to_numeric(df[col], errors='coerce').replace(99, np.nan)\n",
    "      # mean = df[col].mean()\n",
    "      # std = df[col].std()\n",
    "      # df[col] = (df[col] - mean) / std\n",
    "      continue\n",
    "\n",
    "    if (col == 'Global horizontal irradiance / kJ/m2' or col == 'Direct normal irradiance / kJ/m2' or col == 'Diffuse horizontal irradiance / kJ/m2'):\n",
    "      df[col] = pd.to_numeric(df[col], errors='coerce').replace(9999, np.nan)\n",
    "      # mean = df[col].mean()\n",
    "      # std = df[col].std()\n",
    "      #df[col] = (df[col] - mean) / std #can denormalize output\n",
    "      continue\n",
    "    \n",
    "    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "  df.fillna(df.mean(numeric_only=True), inplace=True) #Replace NaN with mean of column for all columns except opaque sky cover which is kept as 99 instead of NaN \n",
    "  df_renamed = df.rename(columns={\n",
    "      'Global horizontal irradiance / kJ/m2': COLUMN_NAMES[\"GHI\"],\n",
    "      'Direct normal irradiance / kJ/m2': COLUMN_NAMES[\"DNI\"],\n",
    "      'Diffuse horizontal irradiance / kJ/m2': COLUMN_NAMES[\"DHI\"],\n",
    "      'Wind speed / 0.1 m/s': COLUMN_NAMES[\"WIND_SPEED\"],\n",
    "      'Opaque sky cover / 0-10 in tenths': COLUMN_NAMES[\"OPAQUE_SKY_COVER\"],\n",
    "      'Wind direction / 0-359 degrees': COLUMN_NAMES[\"WIND_DIRECTION\"],\n",
    "      \"Dry bulb temperature / 0.1 C\": COLUMN_NAMES[\"DRY_BULB_TEMPERATURE\"]\n",
    "  })\n",
    "  df_cloud = df_renamed.copy()\n",
    "  df_cloud, min_year, max_year = fix_opaque_sky_cover(df_cloud)\n",
    "  #print(f\"After fixing opaque sky cover for {station_csv}, min year: {min_year}, max year: {max_year}\")\n",
    "  #min_year = int(min_year)\n",
    "  #max_year = int(max_year)\n",
    "\n",
    "  df_renamed = df_renamed.drop(columns=[COLUMN_NAMES[\"OPAQUE_SKY_COVER\"]], axis=1)\n",
    "  #df_cloud = df_cloud[df_cloud[YEAR_MONTH_DAY_HOUR]>=min_year]\n",
    "  #df_cloud = df_cloud[df_cloud[YEAR_MONTH_DAY_HOUR]<=max_year]\n",
    "  #df_cloud = df_cloud.drop(columns=[YEAR_MONTH_DAY_HOUR], axis=1)\n",
    "  #df_renamed = df_renamed.drop(columns=[YEAR_MONTH_DAY_HOUR], axis=1)\n",
    "  has_cloud_data = True\n",
    "  if not min_year:\n",
    "    has_cloud_data = False\n",
    "    \n",
    "  return df_cloud, df_renamed, station_name.replace(\" \", \"_\"), has_cloud_data\n",
    "\n",
    "def chunk(df, interval = 25):\n",
    "  results = []\n",
    "  for i in range(0, len(df)-interval, 1):\n",
    "    chunk = df[i:i+interval]\n",
    "    results.append(chunk)\n",
    "  results = np.array(results)\n",
    "  return results\n",
    "\n",
    "def get_chunked_tensors(nearest_stations, dfs, interval):\n",
    "  chunked_tensors = []\n",
    "  rows = 0\n",
    "  station_order = []\n",
    "  for index, station in nearest_stations.iterrows():\n",
    "    distanceVector = station.iloc[3][1]\n",
    "    chunked_df = chunk(dfs[rows], interval=interval)\n",
    "    rows+=1\n",
    "    chunkedTensor = torch.tensor(chunked_df).to(torch.float32)\n",
    "    chunked_tensors.append(chunkedTensor)\n",
    "    station_order.append(station)\n",
    "  return chunked_tensors, station_order\n",
    "\n",
    "\n",
    "def create_cleaned_csv_files(csv_files, save_path_cloud, save_path_non_cloud):\n",
    "  for f in csv_files:\n",
    "    df_cloud, df_no_cloud, station_name, has_cloud_data = get_stations_data(f)\n",
    "    print(f\"Saving cleaned data for station {station_name} to: \")\n",
    "    # Save the cleaned DataFrames to the specified paths\n",
    "    \n",
    "    save_path_non_cloud_station = save_path_non_cloud + '/' + station_name + '_no_sky_cover.csv'\n",
    "    print(f\"{save_path_non_cloud_station}\")\n",
    "    if has_cloud_data: #Only saving if data exists\n",
    "      save_path_cloud_station = save_path_cloud + '/' + station_name + '_sky_cover.csv'\n",
    "      df_cloud.to_csv(save_path_cloud_station, index=False)\n",
    "      print(f\"and {save_path_cloud_station} \")\n",
    "    \n",
    "    df_no_cloud.to_csv(save_path_non_cloud_station, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "35690181",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving cleaned data for station ABBOTSFORD_A to: \n",
      "Datasets/CWEEDS_2020_BC_cleaned_non_cloud/ABBOTSFORD_A_no_sky_cover.csv\n",
      "and Datasets/CWEEDS_2020_BC_cleaned_cloud/ABBOTSFORD_A_sky_cover.csv \n",
      "Saving cleaned data for station AGASSIZ_RCS to: \n",
      "Datasets/CWEEDS_2020_BC_cleaned_non_cloud/AGASSIZ_RCS_no_sky_cover.csv\n",
      "Saving cleaned data for station BALLENAS_ISLAND to: \n",
      "Datasets/CWEEDS_2020_BC_cleaned_non_cloud/BALLENAS_ISLAND_no_sky_cover.csv\n",
      "Saving cleaned data for station BLUE_RIVER_CS to: \n",
      "Datasets/CWEEDS_2020_BC_cleaned_non_cloud/BLUE_RIVER_CS_no_sky_cover.csv\n",
      "Saving cleaned data for station BONILLA_ISLAND_(AUT) to: \n",
      "Datasets/CWEEDS_2020_BC_cleaned_non_cloud/BONILLA_ISLAND_(AUT)_no_sky_cover.csv\n",
      "Saving cleaned data for station BURNS_LAKE_DECKER_LAKE to: \n",
      "Datasets/CWEEDS_2020_BC_cleaned_non_cloud/BURNS_LAKE_DECKER_LAKE_no_sky_cover.csv\n",
      "Saving cleaned data for station CALLAGHAN_VALLEY to: \n",
      "Datasets/CWEEDS_2020_BC_cleaned_non_cloud/CALLAGHAN_VALLEY_no_sky_cover.csv\n",
      "Saving cleaned data for station CAPE_ST_JAMES to: \n",
      "Datasets/CWEEDS_2020_BC_cleaned_non_cloud/CAPE_ST_JAMES_no_sky_cover.csv\n",
      "Saving cleaned data for station CATHEDRAL_POINT_(AUT) to: \n",
      "Datasets/CWEEDS_2020_BC_cleaned_non_cloud/CATHEDRAL_POINT_(AUT)_no_sky_cover.csv\n",
      "Saving cleaned data for station CLINTON_(AUT) to: \n",
      "Datasets/CWEEDS_2020_BC_cleaned_non_cloud/CLINTON_(AUT)_no_sky_cover.csv\n",
      "and Datasets/CWEEDS_2020_BC_cleaned_cloud/CLINTON_(AUT)_sky_cover.csv \n",
      "Saving cleaned data for station COMOX_A to: \n",
      "Datasets/CWEEDS_2020_BC_cleaned_non_cloud/COMOX_A_no_sky_cover.csv\n",
      "and Datasets/CWEEDS_2020_BC_cleaned_cloud/COMOX_A_sky_cover.csv \n",
      "Saving cleaned data for station CRANBROOK_A to: \n",
      "Datasets/CWEEDS_2020_BC_cleaned_non_cloud/CRANBROOK_A_no_sky_cover.csv\n",
      "and Datasets/CWEEDS_2020_BC_cleaned_cloud/CRANBROOK_A_sky_cover.csv \n",
      "Saving cleaned data for station CRESTON_CAMPBELL_SCIENTIFIC to: \n",
      "Datasets/CWEEDS_2020_BC_cleaned_non_cloud/CRESTON_CAMPBELL_SCIENTIFIC_no_sky_cover.csv\n",
      "Saving cleaned data for station CUMSHEWA_ISLAND to: \n",
      "Datasets/CWEEDS_2020_BC_cleaned_non_cloud/CUMSHEWA_ISLAND_no_sky_cover.csv\n",
      "Saving cleaned data for station DAWSON_CREEK_A to: \n",
      "Datasets/CWEEDS_2020_BC_cleaned_non_cloud/DAWSON_CREEK_A_no_sky_cover.csv\n",
      "and Datasets/CWEEDS_2020_BC_cleaned_cloud/DAWSON_CREEK_A_sky_cover.csv \n",
      "Saving cleaned data for station DEASE_LAKE_(AUT) to: \n",
      "Datasets/CWEEDS_2020_BC_cleaned_non_cloud/DEASE_LAKE_(AUT)_no_sky_cover.csv\n",
      "Saving cleaned data for station DISCOVERY_ISLAND to: \n",
      "Datasets/CWEEDS_2020_BC_cleaned_non_cloud/DISCOVERY_ISLAND_no_sky_cover.csv\n",
      "Saving cleaned data for station ENTRANCE_ISLAND to: \n",
      "Datasets/CWEEDS_2020_BC_cleaned_non_cloud/ENTRANCE_ISLAND_no_sky_cover.csv\n",
      "Saving cleaned data for station ESQUIMALT_HARBOUR to: \n",
      "Datasets/CWEEDS_2020_BC_cleaned_non_cloud/ESQUIMALT_HARBOUR_no_sky_cover.csv\n",
      "Saving cleaned data for station ESTEVAN_POINT_CS to: \n",
      "Datasets/CWEEDS_2020_BC_cleaned_non_cloud/ESTEVAN_POINT_CS_no_sky_cover.csv\n",
      "Saving cleaned data for station FANNY_ISLAND to: \n",
      "Datasets/CWEEDS_2020_BC_cleaned_non_cloud/FANNY_ISLAND_no_sky_cover.csv\n",
      "Saving cleaned data for station FORT_NELSON_A to: \n",
      "Datasets/CWEEDS_2020_BC_cleaned_non_cloud/FORT_NELSON_A_no_sky_cover.csv\n",
      "and Datasets/CWEEDS_2020_BC_cleaned_cloud/FORT_NELSON_A_sky_cover.csv \n",
      "Saving cleaned data for station FORT_ST_JOHN_A to: \n",
      "Datasets/CWEEDS_2020_BC_cleaned_non_cloud/FORT_ST_JOHN_A_no_sky_cover.csv\n",
      "and Datasets/CWEEDS_2020_BC_cleaned_cloud/FORT_ST_JOHN_A_sky_cover.csv \n",
      "Saving cleaned data for station GREY_ISLET_(AUT) to: \n",
      "Datasets/CWEEDS_2020_BC_cleaned_non_cloud/GREY_ISLET_(AUT)_no_sky_cover.csv\n",
      "Saving cleaned data for station HERBERT_ISLAND_(AUT) to: \n",
      "Datasets/CWEEDS_2020_BC_cleaned_non_cloud/HERBERT_ISLAND_(AUT)_no_sky_cover.csv\n",
      "Saving cleaned data for station HOLLAND_ROCK to: \n",
      "Datasets/CWEEDS_2020_BC_cleaned_non_cloud/HOLLAND_ROCK_no_sky_cover.csv\n",
      "Saving cleaned data for station HOPE_A to: \n",
      "Datasets/CWEEDS_2020_BC_cleaned_non_cloud/HOPE_A_no_sky_cover.csv\n",
      "and Datasets/CWEEDS_2020_BC_cleaned_cloud/HOPE_A_sky_cover.csv \n",
      "Saving cleaned data for station HOWE_SOUND_-_PAM_ROCKS to: \n",
      "Datasets/CWEEDS_2020_BC_cleaned_non_cloud/HOWE_SOUND_-_PAM_ROCKS_no_sky_cover.csv\n",
      "Saving cleaned data for station KAMLOOPS_A to: \n",
      "Datasets/CWEEDS_2020_BC_cleaned_non_cloud/KAMLOOPS_A_no_sky_cover.csv\n",
      "and Datasets/CWEEDS_2020_BC_cleaned_cloud/KAMLOOPS_A_sky_cover.csv \n",
      "Saving cleaned data for station KELOWNA to: \n",
      "Datasets/CWEEDS_2020_BC_cleaned_non_cloud/KELOWNA_no_sky_cover.csv\n",
      "and Datasets/CWEEDS_2020_BC_cleaned_cloud/KELOWNA_sky_cover.csv \n",
      "Saving cleaned data for station KINDAKUN_ROCKS_(AUT) to: \n",
      "Datasets/CWEEDS_2020_BC_cleaned_non_cloud/KINDAKUN_ROCKS_(AUT)_no_sky_cover.csv\n",
      "Saving cleaned data for station LANGARA_ISLAND_RCS to: \n",
      "Datasets/CWEEDS_2020_BC_cleaned_non_cloud/LANGARA_ISLAND_RCS_no_sky_cover.csv\n",
      "Saving cleaned data for station LILLOOET to: \n",
      "Datasets/CWEEDS_2020_BC_cleaned_non_cloud/LILLOOET_no_sky_cover.csv\n",
      "Saving cleaned data for station LUCY_ISLAND_LIGHTSTATION to: \n",
      "Datasets/CWEEDS_2020_BC_cleaned_non_cloud/LUCY_ISLAND_LIGHTSTATION_no_sky_cover.csv\n",
      "Saving cleaned data for station LYTTON_RCS to: \n",
      "Datasets/CWEEDS_2020_BC_cleaned_non_cloud/LYTTON_RCS_no_sky_cover.csv\n",
      "and Datasets/CWEEDS_2020_BC_cleaned_cloud/LYTTON_RCS_sky_cover.csv \n",
      "Saving cleaned data for station MACKENZIE to: \n",
      "Datasets/CWEEDS_2020_BC_cleaned_non_cloud/MACKENZIE_no_sky_cover.csv\n",
      "and Datasets/CWEEDS_2020_BC_cleaned_cloud/MACKENZIE_sky_cover.csv \n",
      "Saving cleaned data for station MALAHAT to: \n",
      "Datasets/CWEEDS_2020_BC_cleaned_non_cloud/MALAHAT_no_sky_cover.csv\n",
      "Saving cleaned data for station NAKUSP_CS to: \n",
      "Datasets/CWEEDS_2020_BC_cleaned_non_cloud/NAKUSP_CS_no_sky_cover.csv\n",
      "Saving cleaned data for station NELSON_CS to: \n",
      "Datasets/CWEEDS_2020_BC_cleaned_non_cloud/NELSON_CS_no_sky_cover.csv\n",
      "Saving cleaned data for station OSOYOOS_CS to: \n",
      "Datasets/CWEEDS_2020_BC_cleaned_non_cloud/OSOYOOS_CS_no_sky_cover.csv\n",
      "Saving cleaned data for station PEMBERTON_AIRPORT_CS to: \n",
      "Datasets/CWEEDS_2020_BC_cleaned_non_cloud/PEMBERTON_AIRPORT_CS_no_sky_cover.csv\n",
      "Saving cleaned data for station PENTICTON_A to: \n",
      "Datasets/CWEEDS_2020_BC_cleaned_non_cloud/PENTICTON_A_no_sky_cover.csv\n",
      "and Datasets/CWEEDS_2020_BC_cleaned_cloud/PENTICTON_A_sky_cover.csv \n",
      "Saving cleaned data for station PITT_MEADOWS_CS to: \n",
      "Datasets/CWEEDS_2020_BC_cleaned_non_cloud/PITT_MEADOWS_CS_no_sky_cover.csv\n",
      "Saving cleaned data for station POINT_ATKINSON to: \n",
      "Datasets/CWEEDS_2020_BC_cleaned_non_cloud/POINT_ATKINSON_no_sky_cover.csv\n",
      "Saving cleaned data for station PORT_HARDY_A to: \n",
      "Datasets/CWEEDS_2020_BC_cleaned_non_cloud/PORT_HARDY_A_no_sky_cover.csv\n",
      "and Datasets/CWEEDS_2020_BC_cleaned_cloud/PORT_HARDY_A_sky_cover.csv \n",
      "Saving cleaned data for station PRINCE_GEORGE to: \n",
      "Datasets/CWEEDS_2020_BC_cleaned_non_cloud/PRINCE_GEORGE_no_sky_cover.csv\n",
      "and Datasets/CWEEDS_2020_BC_cleaned_cloud/PRINCE_GEORGE_sky_cover.csv \n",
      "Saving cleaned data for station PRINCE_RUPERT to: \n",
      "Datasets/CWEEDS_2020_BC_cleaned_non_cloud/PRINCE_RUPERT_no_sky_cover.csv\n",
      "and Datasets/CWEEDS_2020_BC_cleaned_cloud/PRINCE_RUPERT_sky_cover.csv \n",
      "Saving cleaned data for station PRINCETON_CS to: \n",
      "Datasets/CWEEDS_2020_BC_cleaned_non_cloud/PRINCETON_CS_no_sky_cover.csv\n",
      "Saving cleaned data for station PUNTZI_MOUNTAIN_(AUT) to: \n",
      "Datasets/CWEEDS_2020_BC_cleaned_non_cloud/PUNTZI_MOUNTAIN_(AUT)_no_sky_cover.csv\n",
      "Saving cleaned data for station QUESNEL to: \n",
      "Datasets/CWEEDS_2020_BC_cleaned_non_cloud/QUESNEL_no_sky_cover.csv\n",
      "and Datasets/CWEEDS_2020_BC_cleaned_cloud/QUESNEL_sky_cover.csv \n",
      "Saving cleaned data for station REVELSTOKE_A to: \n",
      "Datasets/CWEEDS_2020_BC_cleaned_non_cloud/REVELSTOKE_A_no_sky_cover.csv\n",
      "and Datasets/CWEEDS_2020_BC_cleaned_cloud/REVELSTOKE_A_sky_cover.csv \n",
      "Saving cleaned data for station ROSE_SPIT_(AUT) to: \n",
      "Datasets/CWEEDS_2020_BC_cleaned_non_cloud/ROSE_SPIT_(AUT)_no_sky_cover.csv\n",
      "Saving cleaned data for station SALMON_ARM_CS to: \n",
      "Datasets/CWEEDS_2020_BC_cleaned_non_cloud/SALMON_ARM_CS_no_sky_cover.csv\n",
      "Saving cleaned data for station SANDHEADS_CS to: \n",
      "Datasets/CWEEDS_2020_BC_cleaned_non_cloud/SANDHEADS_CS_no_sky_cover.csv\n",
      "Saving cleaned data for station SANDSPIT to: \n",
      "Datasets/CWEEDS_2020_BC_cleaned_non_cloud/SANDSPIT_no_sky_cover.csv\n",
      "and Datasets/CWEEDS_2020_BC_cleaned_cloud/SANDSPIT_sky_cover.csv \n",
      "Saving cleaned data for station SARTINE_ISLAND_(AUT) to: \n",
      "Datasets/CWEEDS_2020_BC_cleaned_non_cloud/SARTINE_ISLAND_(AUT)_no_sky_cover.csv\n",
      "Saving cleaned data for station SATURNA_ISLAND_CS to: \n",
      "Datasets/CWEEDS_2020_BC_cleaned_non_cloud/SATURNA_ISLAND_CS_no_sky_cover.csv\n",
      "Saving cleaned data for station SHERINGHAM_POINT to: \n",
      "Datasets/CWEEDS_2020_BC_cleaned_non_cloud/SHERINGHAM_POINT_no_sky_cover.csv\n",
      "Saving cleaned data for station SISTERS_ISLAND to: \n",
      "Datasets/CWEEDS_2020_BC_cleaned_non_cloud/SISTERS_ISLAND_no_sky_cover.csv\n",
      "Saving cleaned data for station SMITHERS to: \n",
      "Datasets/CWEEDS_2020_BC_cleaned_non_cloud/SMITHERS_no_sky_cover.csv\n",
      "and Datasets/CWEEDS_2020_BC_cleaned_cloud/SMITHERS_sky_cover.csv \n",
      "Saving cleaned data for station SOLANDER_ISLAND_(AUT) to: \n",
      "Datasets/CWEEDS_2020_BC_cleaned_non_cloud/SOLANDER_ISLAND_(AUT)_no_sky_cover.csv\n",
      "Saving cleaned data for station SPARWOOD_CS to: \n",
      "Datasets/CWEEDS_2020_BC_cleaned_non_cloud/SPARWOOD_CS_no_sky_cover.csv\n",
      "Saving cleaned data for station SQUAMISH_AIRPORT to: \n",
      "Datasets/CWEEDS_2020_BC_cleaned_non_cloud/SQUAMISH_AIRPORT_no_sky_cover.csv\n",
      "Saving cleaned data for station SUMMERLAND_CS to: \n",
      "Datasets/CWEEDS_2020_BC_cleaned_non_cloud/SUMMERLAND_CS_no_sky_cover.csv\n",
      "Saving cleaned data for station TATLAYOKO_LAKE_RCS to: \n",
      "Datasets/CWEEDS_2020_BC_cleaned_non_cloud/TATLAYOKO_LAKE_RCS_no_sky_cover.csv\n",
      "Saving cleaned data for station TERRACE_A to: \n",
      "Datasets/CWEEDS_2020_BC_cleaned_non_cloud/TERRACE_A_no_sky_cover.csv\n",
      "and Datasets/CWEEDS_2020_BC_cleaned_cloud/TERRACE_A_sky_cover.csv \n",
      "Saving cleaned data for station VANCOUVER_INTL_A to: \n",
      "Datasets/CWEEDS_2020_BC_cleaned_non_cloud/VANCOUVER_INTL_A_no_sky_cover.csv\n",
      "and Datasets/CWEEDS_2020_BC_cleaned_cloud/VANCOUVER_INTL_A_sky_cover.csv \n",
      "Saving cleaned data for station VERNON_AUTO to: \n",
      "Datasets/CWEEDS_2020_BC_cleaned_non_cloud/VERNON_AUTO_no_sky_cover.csv\n",
      "Saving cleaned data for station VICTORIA_GONZALES_CS to: \n",
      "Datasets/CWEEDS_2020_BC_cleaned_non_cloud/VICTORIA_GONZALES_CS_no_sky_cover.csv\n",
      "Saving cleaned data for station VICTORIA_HARTLAND_CS to: \n",
      "Datasets/CWEEDS_2020_BC_cleaned_non_cloud/VICTORIA_HARTLAND_CS_no_sky_cover.csv\n",
      "Saving cleaned data for station VICTORIA_INTL_A to: \n",
      "Datasets/CWEEDS_2020_BC_cleaned_non_cloud/VICTORIA_INTL_A_no_sky_cover.csv\n",
      "and Datasets/CWEEDS_2020_BC_cleaned_cloud/VICTORIA_INTL_A_sky_cover.csv \n",
      "Saving cleaned data for station VICTORIA_UNIVERSITY_CS to: \n",
      "Datasets/CWEEDS_2020_BC_cleaned_non_cloud/VICTORIA_UNIVERSITY_CS_no_sky_cover.csv\n",
      "Saving cleaned data for station WARFIELD_RCS to: \n",
      "Datasets/CWEEDS_2020_BC_cleaned_non_cloud/WARFIELD_RCS_no_sky_cover.csv\n",
      "Saving cleaned data for station WEST_VANCOUVER_AUT to: \n",
      "Datasets/CWEEDS_2020_BC_cleaned_non_cloud/WEST_VANCOUVER_AUT_no_sky_cover.csv\n",
      "Saving cleaned data for station WHISTLER_-_NESTERS to: \n",
      "Datasets/CWEEDS_2020_BC_cleaned_non_cloud/WHISTLER_-_NESTERS_no_sky_cover.csv\n",
      "Saving cleaned data for station WHITE_ROCK_CS to: \n",
      "Datasets/CWEEDS_2020_BC_cleaned_non_cloud/WHITE_ROCK_CS_no_sky_cover.csv\n",
      "Saving cleaned data for station WILLIAMS_LAKE_A to: \n",
      "Datasets/CWEEDS_2020_BC_cleaned_non_cloud/WILLIAMS_LAKE_A_no_sky_cover.csv\n",
      "and Datasets/CWEEDS_2020_BC_cleaned_cloud/WILLIAMS_LAKE_A_sky_cover.csv \n",
      "Saving cleaned data for station YOHO_PARK to: \n",
      "Datasets/CWEEDS_2020_BC_cleaned_non_cloud/YOHO_PARK_no_sky_cover.csv\n"
     ]
    }
   ],
   "source": [
    "path = 'Datasets/CWEEDS_2020_BC_raw'\n",
    "csv_files = glob.glob(os.path.join(path, \"*.csv\"))\n",
    "save_path_cloud = 'Datasets/CWEEDS_2020_BC_cleaned_cloud'\n",
    "save_path_non_cloud = 'Datasets/CWEEDS_2020_BC_cleaned_non_cloud'\n",
    "create_cleaned_csv_files(csv_files, save_path_cloud, save_path_non_cloud)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
